# modelscopet2v_lora_finetuned_quantized
Finetuned the model_scope_t2v model using LoRA and Quantization reduced the required memory consumption and load on GPU. This work is heavily inspired from ExponentialML's repo.
